{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "from torchtune.models import convert_weights\n",
    "from torchtune.models.llama3 import llama3_8b, llama3_tokenizer\n",
    "from torchtune.training.checkpointing._checkpointer import safe_torch_load\n",
    "from torchtune import utils\n",
    "from transformers import AutoTokenizer\n",
    "from torchtune.generation import generate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prompt_mimic(note):\n",
    "    return f\"\"\"\n",
    "    You are given a clinical report. Your task is to identify the diseases that the patient have and list them. The result list should be formatted exactly as [disease1, disease2, ...] and be on a single line.\n",
    "\n",
    "    Only use diseases from this list:\n",
    "    ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "    'Lung Opacity', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "    Guidelines:\n",
    "    Be careful about negation. E.g., do not include Pneumonia if the text says \"no Pneumonia\"\n",
    "    Only include diseases that are certain. Entities that are 'likely', 'possibly' should not be returned. \n",
    "    After output the list, provide the evidence in the text for each disease.    \n",
    "    \n",
    "    **Report to Analyze:**\n",
    "    {note}\n",
    "\n",
    "    Expected Output:\n",
    "    \"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f851c4e4e968f1e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "backbone = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
    "model = llama3_8b()\n",
    "model_state_dict = safe_torch_load(\"meta_model_0.pt\")\n",
    "model_state_dict = convert_weights.meta_to_tune(model_state_dict)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a69992388c118e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_row(note):\n",
    "    prompt_str = prompt_mimic(note)\n",
    "\n",
    "    tokens = tokenizer.encode(prompt_str)\n",
    "    prompt = torch.tensor(tokens, dtype=torch.int, device=device)\n",
    "\n",
    "    generated_disease = \"\"\n",
    "    ntry = 0\n",
    "    while (not generated_disease.startswith(\"[\") or not generated_disease.endswith(\"]\")) and ntry < 2:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = generate(\n",
    "                    model=model,\n",
    "                    prompt=prompt,\n",
    "                    max_generated_tokens=150,\n",
    "                    temperature=0,\n",
    "                    stop_tokens=tokenizer.stop_tokens,\n",
    "                    pad_id=tokenizer.pad_id,\n",
    "                )\n",
    "\n",
    "            raw_output = tokenizer.decode(outputs[0])\n",
    "            disease_start = raw_output.find(\"Expected Output:\")\n",
    "            if disease_start != -1:\n",
    "                generated_disease = raw_output[disease_start + len(\"Expected Output:\"):].strip().splitlines()[0]\n",
    "            ntry += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    result = {\n",
    "        \"note\": note,\n",
    "        \"generated_disease\": generated_disease,\n",
    "        \"raw_output\": raw_output,\n",
    "    }\n",
    "\n",
    "    print(\"Generated diseases: \" + generated_disease)\n",
    "    return result\n",
    "\n",
    "df = pd.read_csv(\"radreportx.csv\")\n",
    "print(\"CSV file read successfully.\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        findings = row['note']\n",
    "        print(f\"Processing row {index}...\")\n",
    "        result = process_row(findings)\n",
    "        result['study_id'] = row['study_id']\n",
    "        result['subject_id'] = row['subject_id']\n",
    "        result['mimic_label'] = row['mimic_label']\n",
    "        result['negbio_label'] = row['negbio_label']\n",
    "        result['human_label1'] = row['human_label1']\n",
    "        result['human_label2'] = row['human_label2']\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        print(row['input'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "105fbc532ad04a43"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "findings = f\"\"\"\n",
    "FINDINGS: A cluster of heterogeneous opacities in the right lower lung has \n",
    " has continued to grow since ___. \n",
    "   Otherwise, the lungs are clear. Moderate cardiomegaly, including severe left\n",
    " atrial enlargement is chronic; there is no pulmonary vascular congestion or\n",
    " edema. The thoracic aorta is heavily calcified.  There may be a new small,\n",
    " right pleural effusions or pneumothorax.\n",
    " IMPRESSION: Slowly progressive chronic right pneumonia, could be exogenous\n",
    " lipoid pneumonia, but tuberculosis is in the differential.  CT scanning\n",
    " recommended.  Nurse ___ and I discussed the findings and their\n",
    " clinical significance by telephone at the time of dictation.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "875239ee64508cb0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_str = prompt_mimic(findings)\n",
    "tokens = tokenizer.encode(prompt_str)\n",
    "prompt = torch.tensor(tokens, dtype=torch.int, device=device)\n",
    "\n",
    "generated_disease = ''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ed7754459786c3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(prompt_str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8119d552124738"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = generate(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_generated_tokens=100,\n",
    "        temperature=0\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81d2f93f9ec7923f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "raw_output = tokenizer.decode(outputs[0][0])\n",
    "print(raw_output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca0584947d14d9b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find the extract disease \n",
    "disease_start = raw_output.find(\"Expected Output:\")\n",
    "if disease_start != -1:\n",
    "    generated_disease = raw_output[disease_start + len(\"Expected Output:\"):].strip().splitlines()[0]\n",
    "print(generated_disease)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6275a29f9847e81e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Provide evidence \n",
    "evidence = raw_output.find(\"Evidence:\")\n",
    "generated_evidence = raw_output[evidence + len(\"Evidence:\"):]\n",
    "print(generated_evidence)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f7c4ab64d28b57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
